\section{Introduction}

Elliptic \gls{pdes} describe phenomena in the areas of physics, biology, chemistry, and engineering, among others. In physics, potential fields such as gravitational fields and electromagnetic fields are modeled with elliptic PDEs (the Laplace and Poisson equations). In biology and chemistry, reaction-diffusion systems can be characterized using time-dependent elliptic operators. Engineering examples include heat and mass diffusion, as well as pressure calculations for viscous fluid systems. Scientists and engineers modeling these various phenomena must solve the associated elliptic equations using analytical and/or numerical methods.

Numerical methods for elliptic PDEs are a well-documented area of research and development. Classical methods include finite difference, finite volume, and finite element methods. More modern approaches include higher order versions of classical methods, spectral methods, and meshless approaches like particle based methods or radial basis function techniques. Many discretization approaches results in a system of linear equations that must be solved efficiently and rapidly. Solution methods are categorized into direct and iterative methods, each with their own advantages and disadvantages. Taking advantage of the structure of the linear systems leads to significant increases in memory and compute performance.

Modern computational resources are as diverse as they are extensive. From high-powered laptops, to desktop workstations, to clusters and supercomputers, there are no lack of available platforms for scientific modeling. With diverse hardware and software stacks, the numerical methods developed to solve the aforementioned linear systems should be versatile and adaptable, capable of leveraging the specific characteristics and strengths of each type of hardware. Optimizations such as vectorization, parallelization, and memory access patterns must be carefully considered and implemented to maximize performance across different platforms.

Adaptive mesh refinement (AMR) is a mesh technique used to increase the memory and compute efficiency of numerical solvers for PDEs. AMR techniques collocate more refined meshes around targeted regions of interest, and coarser meshes elsewhere. Higher resolution is particularly beneficial in cases where there are localized regions of error, large gradients, boundaries, and material interfaces. Adaptive meshes can also significantly improve the performance of numerical solvers, at the cost of more complicated implementations. Additional considerations must be accounted for, such as how to handle coarse-fine interfaces, load balancing for parallel algorithms, and more complicated data structures. In the context of elliptic PDEs, AMR further complicates linear solvers; iterative preconditioners must be more sophisticated and expensive matrix factorizations must be recomputed when the mesh is adapted. Although AMR introduces complexities, the benefits often outweigh the costs, as the use of AMR enables the modeling of complex phenomena when more traditional uniform solvers are too computationally expensive.

This dissertation will detail the development of a direct solver for elliptic PDEs that can be efficiently applied to adaptive meshes, as well as to parallel computer architectures. The method is called the \gls{qahps} method. The primary feature of this method is that the factorization is represented as a set of solution operators that can be locally adapted. The method is an adaptive extension of the \gls{hps} method \citep{gillman2014direct} and targets a tree-based AMR approach as implemented in the \pforest software library \citep{burstedde2011p4est}. Building the factorization set can be done with $\mathcal{O}(N^{3/2})$ complexity, with $\mathcal{O}(N)$ complexity for subsequent solves. Parallelization is handled for distributed memory computer architectures through the \gls{mpi}. It will be shown that the method motivated and developed herein is competitive with other codes and solvers, including iterative solvers for elliptic PDEs.