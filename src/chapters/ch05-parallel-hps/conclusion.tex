\section{Conclusion}

The work presented in this paper demonstrates a successful implementation of the quadtree-adaptive Hierarchical Poincar√©-Steklov (HPS) method in parallel. The integration of the \pforest\ library, known for its efficiency and scalability, with the communication patterns of the quadtree-adaptive HPS method, shows promise for an effective solver for elliptic PDEs. As distributed memory architectures are increasingly more common in commodity clusters, an MPI implementation is essential for future scalability.

Running strong and weak scaling analysis on Polaris, one of the world's top 50 fastest supercomputers, provides insights into potential and necessary improvements for further optimizations. The current bottleneck is the communication required for the family callbacks during family traversals of the path-indexed quadtree. Potential optimizations include reducing redundant calculations through more efficient matrix partitioning and investigating non-blocking communication to better overlap compute and communication. These insights are currently being investigated and integrated into EllipticForest \citep{chipman2024ellipticforest}.